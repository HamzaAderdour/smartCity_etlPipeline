# Pipeline ETL pour l'analyse de donnÃ©es de capteurs IoT

## Description
Ce projet implÃ©mente un pipeline ETL complet pour l'analyse en temps rÃ©el des donnÃ©es de capteurs IoT dans une ville intelligente. Le systÃ¨me collecte, traite et analyse les donnÃ©es de tempÃ©rature, d'humiditÃ© et de pollution provenant de capteurs rÃ©partis dans diffÃ©rents quartiers.

## Architecture
- **Ingestion de donnÃ©es** : Kafka pour la collecte en temps rÃ©el
- **Orchestration** : Airflow pour la gestion du pipeline ETL
- **Traitement** : Celery pour les tÃ¢ches de transformation et d'agrÃ©gation
- **Stockage** : Elasticsearch pour le stockage et la recherche
- **API** : FastAPI pour l'exposition des donnÃ©es
- **Interface** : React.js pour la visualisation
- **Monitoring** : Prometheus & Grafana

## Structure du projet
```
â”œâ”€â”€ ğŸ“‚ config/           # Fichiers de configuration
â”œâ”€â”€ ğŸ“‚ data-ingestion/   # Composants d'ingestion Kafka
â”œâ”€â”€ ğŸ“‚ etl-pipeline/     # Pipeline ETL (Airflow, Celery)
â”œâ”€â”€ ğŸ“‚ data-storage/     # Stockage Elasticsearch
â”œâ”€â”€ ğŸ“‚ api/             # API FastAPI
```

## Installation
1. Cloner le repository
2. Installer les dÃ©pendances : `pip install -r requirements.txt`
3. Configurer les variables d'environnement
4. Lancer les services (instructions dÃ©taillÃ©es Ã  venir)

## Configuration
Les fichiers de configuration se trouvent dans le dossier `config/` :
- `airflow.cfg` : Configuration Airflow
- `kafka.yml` : Configuration Kafka
- `elasticsearch.yml` : Configuration Elasticsearch
- `env.yml` : Variables d'environnement

## DÃ©veloppement
Instructions pour le dÃ©veloppement Ã  venir...

## Licence
PropriÃ©taire - Tous droits rÃ©servÃ©s 